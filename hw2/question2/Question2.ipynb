{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "b)\n",
    "<br>How many samples (dishes) are there in the training set?\n",
    "<br> Sample number: 39774\n",
    "<br> How many categories (types of cuisine)?\n",
    "<br> Category number: 20\n",
    "<br> How many unique ingredients are there?\n",
    "<br> Ingredient number: 6714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 39774\n",
      "Category number: 20\n",
      "Ingredient number: 6714\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('train.json', 'r') as f:\n",
    "     train_raw_data = json.load(f)\n",
    "with open('test.json', 'r') as f:\n",
    "     test_raw_data = json.load(f)\n",
    "cuisines=set([i['cuisine'] for i in data])\n",
    "ingredients=set()\n",
    "for i in [i['ingredients'] for i in data]:\n",
    "    ingredients |= set(i)\n",
    "print(\"Sample number:\", len(data))\n",
    "print(\"Category number:\",len(cuisines))\n",
    "print(\"Ingredient number:\",len(ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients=list(ingredients)\n",
    "train_data,train_labels,test_data,test_ids=[],[],[],[]\n",
    "for sample in train_raw_data:\n",
    "    sampleArr=[0]*len(ingredients)\n",
    "    for i in sample['ingredients']:\n",
    "        sampleArr[ingredients.index(i)]=1\n",
    "    train_data.append(sampleArr)\n",
    "    train_labels.append(sample['cuisine'])\n",
    "for sample in test_raw_data:\n",
    "    sampleArr=[0]*len(ingredients)\n",
    "    for i in sample['ingredients']:\n",
    "        if i in ingredients: sampleArr[ingredients.index(i)]=1\n",
    "    test_data.append(sampleArr)\n",
    "    test_ids.append(sample['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)\n",
    "##### Gaussian prior 3 fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 13258 points : 8233\n",
      "Number of mislabeled points out of a total 13258 points : 8181\n",
      "Number of mislabeled points out of a total 13258 points : 8252\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets,cross_validation,linear_model\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "\n",
    "for train, test in (cross_validation.KFold(len(train_data), n_folds=3)):\n",
    "    cv_train_data=np.array(train_data)[train]\n",
    "    cv_train_labels=np.array(train_labels)[train]\n",
    "    cv_test_data=np.array(train_data)[test]\n",
    "    cv_test_labels=np.array(train_labels)[test]\n",
    "    gnb = GaussianNB().fit(cv_train_data, cv_train_labels)\n",
    "    y_pred = gnb.predict(cv_test_data)\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d\" % (cv_test_data.shape[0],(cv_test_labels != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bernoulli prior 3 fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 13258 points : 4187\n",
      "Number of mislabeled points out of a total 13258 points : 4249\n",
      "Number of mislabeled points out of a total 13258 points : 4151\n"
     ]
    }
   ],
   "source": [
    "for train, test in (cross_validation.KFold(len(train_data), n_folds=3)):\n",
    "    cv_train_data=np.array(train_data)[train]\n",
    "    cv_train_labels=np.array(train_labels)[train]\n",
    "    cv_test_data=np.array(train_data)[test]\n",
    "    cv_test_labels=np.array(train_labels)[test]\n",
    "    bnb = BernoulliNB().fit(cv_train_data, cv_train_labels)\n",
    "    y_pred = bnb.predict(cv_test_data)\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d\" % (cv_test_data.shape[0],(cv_test_labels != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multivariate Bernoulli event model, features are independent booleans (binary variables) describing inputs.\n",
    "Bernoulli event model is especially popular for classifying short texts. \n",
    "It has the benefit of explicitly modelling the absence of terms. \n",
    "However, in this case, the missing ingredients of a cuisine are not considerably important with respect to training the classifier of cuisine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 13258 points : 2972\n",
      "Number of mislabeled points out of a total 13258 points : 3021\n",
      "Number of mislabeled points out of a total 13258 points : 2934\n"
     ]
    }
   ],
   "source": [
    "for train, test in (cross_validation.KFold(len(train_data), n_folds=3)):\n",
    "    cv_train_data=np.array(train_data)[train]\n",
    "    cv_train_labels=np.array(train_labels)[train]\n",
    "    cv_test_data=np.array(train_data)[test]\n",
    "    cv_test_labels=np.array(train_labels)[test]\n",
    "    lr = linear_model.LogisticRegression(multi_class='ovr')\n",
    "    lr.fit(cv_train_data, cv_train_labels)\n",
    "    y_pred = lr.predict(cv_test_data)\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d\" % (cv_test_data.shape[0],(cv_test_labels != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "lr = linear_model.LogisticRegression(multi_class='ovr')\n",
    "lr.fit(train_data, train_labels)\n",
    "y_pred = lr.predict(test_data)\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    spamwriter.writerow(['id','cuisine'])\n",
    "    for i,label in enumerate(y_pred):\n",
    "        spamwriter.writerow([test_ids[i],label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
